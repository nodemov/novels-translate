import requests
import json
import time
import os
from typing import List
import re

class NovelTranslator:
    def __init__(self, model_name="scb10x/typhoon-translate-4b", ollama_url="http://localhost:11434"):
        self.model_name = model_name
        self.ollama_url = ollama_url
        self.api_url = f"{ollama_url}/api/generate"
        
    def chunk_text(self, text: str, max_chunk_size: int = 2000) -> List[str]:
        """‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô chunks ‡πÇ‡∏î‡∏¢‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ï‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ"""
        # ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤
        paragraphs = text.split('\n\n')
        chunks = []
        current_chunk = ""
        
        for paragraph in paragraphs:
            # ‡∏ñ‡πâ‡∏≤‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ + chunk ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î
            if len(current_chunk + paragraph) < max_chunk_size:
                current_chunk += paragraph + "\n\n"
            else:
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å chunk ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏° chunk ‡πÉ‡∏´‡∏°‡πà
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                current_chunk = paragraph + "\n\n"
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° chunk ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
            
        return chunks
    
    def clean_translation_output(self, text: str) -> str:
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡πÇ‡∏î‡∏¢‡∏•‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å"""
        # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡∏≠‡∏≠‡∏Å
        unwanted_phrases = [
            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ô‡∏±‡∏Å‡πÅ‡∏õ‡∏•‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û",
            "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÅ‡∏õ‡∏•‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ",
            "‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•:",
            "‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•:",
            "‡πÅ‡∏õ‡∏•‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢",
            "‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®",
            "‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢",
            "‡πÅ‡∏õ‡∏•‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞:",
            "‡∏Ñ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£",
            "‡∏õ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤",
            "‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡πÅ‡∏•‡∏∞‡∏™‡πÑ‡∏ï‡∏•‡πå",
            "1.", "2.", "3.", "4.", "5.", "6."
        ]
        
        lines = text.split('\n')
        cleaned_lines = []
        
        for line in lines:
            line = line.strip()
            # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            if not line:
                continue
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            should_skip = False
            for phrase in unwanted_phrases:
                if phrase in line:
                    should_skip = True
                    break
            
            # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÅ‡∏•‡∏∞‡∏à‡∏∏‡∏î (‡πÄ‡∏ä‡πà‡∏ô "1.", "2.")
            if line.strip() in ['1.', '2.', '3.', '4.', '5.', '6.']:
                should_skip = True
            
            if not should_skip:
                cleaned_lines.append(line)
        
        # ‡∏£‡∏ß‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥
        result = '\n'.join(cleaned_lines)
        
        # ‡∏•‡∏ö‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô‡∏≠‡∏≠‡∏Å
        while '\n\n\n' in result:
            result = result.replace('\n\n\n', '\n\n')
        
        return result.strip()
    
    def translate_chunk(self, text: str) -> str:
        """‡πÅ‡∏õ‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° chunk ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß"""
        prompt = f"""‡πÅ‡∏õ‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢ Wuxia/Xianxia ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏ß‡πâ:

{text}"""

        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.2,      # Lower for more consistent translation
                "top_p": 0.85,           # Better focus on likely translations
                "max_tokens": 6000,      # Increased for longer Thai translations
                "num_ctx": 16384,        # Increased context window for better coherence
                "repeat_penalty": 1.1,   # Prevent repetitive phrases
                "top_k": 40             # Limit vocabulary choices for quality
            }
        }
        
        try:
            response = requests.post(self.api_url, json=payload, timeout=300)
            response.raise_for_status()
            result = response.json()
            
            if 'response' in result:
                # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô
                cleaned_result = self.clean_translation_output(result['response'])
                return cleaned_result
            else:
                print(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: ‡πÑ‡∏°‡πà‡∏û‡∏ö response ‡πÉ‡∏ô result")
                return text
                
        except requests.exceptions.Timeout:
            print("‡∏´‡∏°‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏≠ - ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà...")
            time.sleep(5)
            return self.translate_chunk(text)  # ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà
        except requests.exceptions.RequestException as e:
            print(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠: {e}")
            return text
        except Exception as e:
            print(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
            return text
    
    def translate_file(self, input_file: str, output_file: str, chunk_size: int = 2000, 
                      delay_between_chunks: float = 1.0) -> None:
        """‡πÅ‡∏õ‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
        print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå: {input_file}")
        
        # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        try:
            with open(input_file, 'r', encoding='utf-8') as f:
                content = f.read()
        except FileNotFoundError:
            print(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {input_file}")
            return
        except UnicodeDecodeError:
            # ‡∏•‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ encoding ‡∏≠‡∏∑‡πà‡∏ô
            encodings = ['utf-8', 'cp1252', 'iso-8859-1']
            content = None
            for encoding in encodings:
                try:
                    with open(input_file, 'r', encoding=encoding) as f:
                        content = f.read()
                    print(f"‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏î‡πâ‡∏ß‡∏¢ encoding: {encoding}")
                    break
                except UnicodeDecodeError:
                    continue
            
            if content is None:
                print("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ")
                return
        
        # ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô chunks
        chunks = self.chunk_text(content, chunk_size)
        total_chunks = len(chunks)
        
        print(f"‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô {total_chunks} ‡∏™‡πà‡∏ß‡∏ô")
        print("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•...")
        
        translated_chunks = []
        
        # ‡πÅ‡∏õ‡∏•‡∏ó‡∏µ‡∏•‡∏∞ chunk
        for i, chunk in enumerate(chunks, 1):
            print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà {i}/{total_chunks}")
            
            translated = self.translate_chunk(chunk)
            translated_chunks.append(translated)
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤
            progress = (i / total_chunks) * 100
            print(f"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤: {progress:.1f}%")
            
            # ‡∏£‡∏≠‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á chunks ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
            if i < total_chunks:
                time.sleep(delay_between_chunks)
        
        # ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•
        translated_content = "\n\n".join(translated_chunks)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(translated_content)
            print(f"\n‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: {output_file}")
        except Exception as e:
            print(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {e}")
    
    def translate_directory(self, input_dir: str, output_dir: str, 
                           file_extensions: List[str] = ['.txt'], **kwargs) -> None:
        """‡πÅ‡∏õ‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå"""
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        for filename in os.listdir(input_dir):
            if any(filename.lower().endswith(ext) for ext in file_extensions):
                input_path = os.path.join(input_dir, filename)
                output_filename = f"translated_{filename}"
                output_path = os.path.join(output_dir, output_filename)
                
                print(f"\n{'='*50}")
                print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•: {filename}")
                print(f"{'='*50}")
                
                self.translate_file(input_path, output_path, **kwargs)

def main():
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á translator instance
    translator = NovelTranslator()
    
    print("üîÑ Novel Translator for Ollama")
    print("=" * 40)
    
    while True:
        print("\n‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î:")
        print("1. ‡πÅ‡∏õ‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß")
        print("2. ‡πÅ‡∏õ‡∏•‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå") 
        print("3. ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
        
        choice = input("\n‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (1-3): ").strip()
        
        if choice == "1":
            # ‡πÅ‡∏õ‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
            input_file = input("‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö: ").strip()
            if not input_file:
                continue
                
            if not os.path.exists(input_file):
                print("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏")
                continue
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            base_name = os.path.splitext(input_file)[0]
            output_file = f"{base_name}_translated.txt"
            
            # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
            chunk_size = input("‡∏Ç‡∏ô‡∏≤‡∏î chunk (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô 2000): ").strip()
            chunk_size = int(chunk_size) if chunk_size.isdigit() else 2000
            
            delay = input("‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á chunks ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô 1): ").strip()
            delay = float(delay) if delay.replace('.','').isdigit() else 1.0
            
            translator.translate_file(input_file, output_file, chunk_size, delay)
            
        elif choice == "2":
            # ‡πÅ‡∏õ‡∏•‡∏ó‡∏±‡πâ‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
            input_dir = input("‡∏£‡∏∞‡∏ö‡∏∏‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö: ").strip()
            if not input_dir or not os.path.exists(input_dir):
                print("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏")
                continue
            
            output_dir = input("‡∏£‡∏∞‡∏ö‡∏∏‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô translated_novels): ").strip()
            output_dir = output_dir if output_dir else "translated_novels"
            
            # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
            extensions_input = input("‡∏£‡∏∞‡∏ö‡∏∏‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•‡πÑ‡∏ü‡∏•‡πå (.txt,.md ‡∏´‡∏£‡∏∑‡∏≠ enter ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô): ").strip()
            extensions = [ext.strip() for ext in extensions_input.split(',')] if extensions_input else ['.txt']
            
            chunk_size = input("‡∏Ç‡∏ô‡∏≤‡∏î chunk (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô 2000): ").strip()
            chunk_size = int(chunk_size) if chunk_size.isdigit() else 2000
            
            delay = input("‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á chunks ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô 1): ").strip()
            delay = float(delay) if delay.replace('.','').isdigit() else 1.0
            
            translator.translate_directory(input_dir, output_dir, extensions, 
                                         chunk_size=chunk_size, delay_between_chunks=delay)
            
        elif choice == "3":
            print("‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
            break
        else:
            print("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 1-3")

if __name__ == "__main__":
    main()